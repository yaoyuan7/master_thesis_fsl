{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(directory):\n",
    "    list_dir = os.listdir(directory)\n",
    "    list_dir = sorted(list_dir)\n",
    "    \n",
    "    train_acc, train_loss, val_acc, val_loss = [],[],[],[]\n",
    "    with open(directory+'/'+list_dir[0],'r') as f:\n",
    "        for line in f:\n",
    "            train_acc.append(float(line.rstrip('\\n')))\n",
    "    with open(directory+'/'+list_dir[1],'r') as f:\n",
    "        for line in f:\n",
    "            train_loss.append(float(line.rstrip('\\n')))  \n",
    "    with open(directory+'/'+list_dir[2],'r') as f:\n",
    "        for line in f:\n",
    "            val_acc.append(float(line.rstrip('\\n')))  \n",
    "    with open(directory+'/'+list_dir[3],'r') as f:\n",
    "        for line in f:\n",
    "            val_loss.append(float(line.rstrip('\\n')))  \n",
    "\n",
    "    return train_acc,train_loss,val_acc,val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "\n",
    "    return m, m-h, m+h\n",
    "\n",
    "def return_highest(input_list,interval):\n",
    "    tmp_mean, tmp_diff, index = 0, 0, 0\n",
    "    for i in range(len(input_list)-interval):\n",
    "        mean, high, low = mean_confidence_interval(input_list[i:interval+i])\n",
    "        if mean > tmp_mean:\n",
    "            tmp_mean = mean\n",
    "            tmp_diff = high-mean\n",
    "            index = i\n",
    "\n",
    "    return tmp_mean,-tmp_diff, index, interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_51201_training_acc, _51201_training_loss, _51201_val_acc, _51201_val_loss = read_file('51201/')\n",
    "_51205_training_acc, _51205_training_loss, _51205_val_acc, _51205_val_loss = read_file('51205/')\n",
    "_55201_training_acc, _55201_training_loss, _55201_val_acc, _55201_val_loss = read_file('55201/')\n",
    "_55205_training_acc, _55205_training_loss, _55205_val_acc, _55205_val_loss = read_file('55205/')\n",
    "\n",
    "_201201_training_acc, _201201_training_loss, _201201_val_acc, _201201_val_loss = read_file('201201/')\n",
    "_201205_training_acc, _201205_training_loss, _201205_val_acc, _201205_val_loss = read_file('201205/')\n",
    "_205201_training_acc, _205201_training_loss, _205201_val_acc, _205201_val_loss = read_file('205201/')\n",
    "_205205_training_acc, _205205_training_loss, _205205_val_acc, _205205_val_loss = read_file('205205/')\n",
    "\n",
    "_601201_training_acc, _601201_training_loss, _601201_val_acc, _601201_val_loss = read_file('601201/')\n",
    "_601205_training_acc, _601205_training_loss, _601205_val_acc, _601205_val_loss = read_file('601205/')\n",
    "_605201_training_acc, _605201_training_loss, _605201_val_acc, _605201_val_loss = read_file('605201/')\n",
    "_605205_training_acc, _605205_training_loss, _605205_val_acc, _605205_val_loss = read_file('605205/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_figure(training_acc,training_loss,val_acc,val_loss,le_name,title,save_name,save_op=False,alpha=1):\n",
    "    \n",
    "    flatui = [\"#001871\",\"#e48d2c\",\"#c90000\",\"#43bcff\", \"#138d90\", \"#000000\"]\n",
    "    len_train = int(len(training_acc[0])*alpha)\n",
    "    len_test = int(len(val_acc[0])*alpha)\n",
    "\n",
    "    training = np.arange(0, len_train, 10)\n",
    "    val = np.arange(0, len_train, int(len_train/len_test))\n",
    "\n",
    "    fig = plt.figure(figsize=(25,16))\n",
    "    #fig.suptitle(title,fontsize=24)\n",
    "\n",
    "#     ax1=plt.subplot(2, 2, 1)\n",
    "#     ax1.set_color_cycle(sns.color_palette(flatui))\n",
    "#     plt.xticks(fontsize=18)\n",
    "#     plt.yticks(fontsize=18)\n",
    "#     for i in range(len(le_name)):\n",
    "#         plt.plot(training, training_loss[i][0:len_train:10])\n",
    "#     plt.xlabel('iteration', fontsize=18)\n",
    "#     plt.ylabel('Training Loss', fontsize=18)\n",
    "#     plt.gca().legend(le_name, fontsize=18)\n",
    "\n",
    "#     ax2=plt.subplot(2, 2, 2)\n",
    "#     ax2.set_color_cycle(sns.color_palette(flatui))\n",
    "#     plt.xticks(fontsize=18)\n",
    "#     plt.yticks(fontsize=18)\n",
    "#     for i in range(len(le_name)):\n",
    "#         plt.plot(val, val_loss[i][0:len_test])\n",
    "#     plt.xlabel('iteration', fontsize=18)\n",
    "#     plt.ylabel('Testing Loss', fontsize=18)\n",
    "#     plt.gca().legend(le_name, fontsize=18)\n",
    "\n",
    "#     ax3=plt.subplot(2, 2, 3)\n",
    "#     ax3.set_color_cycle(sns.color_palette(flatui))\n",
    "#     plt.xticks(fontsize=18)\n",
    "#     plt.yticks(fontsize=18)\n",
    "#     for i in range(len(le_name)):\n",
    "#         plt.plot(training, training_acc[i][0:len_train:10])\n",
    "#     plt.xlabel('iteration', fontsize=18)\n",
    "#     plt.ylabel('Training Accuracy', fontsize=18)\n",
    "#     plt.gca().legend(le_name, fontsize=18)\n",
    "\n",
    "    ax4=plt.subplot(1, 1, 1)\n",
    "    ax4.set_color_cycle(sns.color_palette(flatui))\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    for i in range(len(le_name)):\n",
    "        plt.plot(val, val_acc[i][0:len_test],linewidth=3)\n",
    "    plt.xlabel('iteration', fontsize=18)\n",
    "    plt.ylabel('Testing Accuracy', fontsize=18)\n",
    "    plt.gca().legend(le_name, fontsize=18,prop={'size': 24})\n",
    "    #,prop={'size': 24}\n",
    "    if save_op:\n",
    "        fig.savefig(save_name,bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_5155_training_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-12178ff0e463>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m training_loss = [_5155_training_loss,_20155_training_loss,_60155_training_loss,\n\u001b[0m\u001b[1;32m      2\u001b[0m                  _5555_training_loss,_20555_training_loss,_60555_training_loss]\n\u001b[1;32m      3\u001b[0m training_acc = [_5155_training_acc,_20155_training_acc,_60155_training_acc,\n\u001b[1;32m      4\u001b[0m                 _5555_training_acc,_20555_training_acc,_60555_training_acc]\n\u001b[1;32m      5\u001b[0m val_loss = [_5155_val_loss,_20155_val_loss,_60155_val_loss,\n",
      "\u001b[0;31mNameError\u001b[0m: name '_5155_training_loss' is not defined"
     ]
    }
   ],
   "source": [
    "training_loss = [_5155_training_loss,_20155_training_loss,_60155_training_loss,\n",
    "                 _5555_training_loss,_20555_training_loss,_60555_training_loss]\n",
    "training_acc = [_5155_training_acc,_20155_training_acc,_60155_training_acc,\n",
    "                _5555_training_acc,_20555_training_acc,_60555_training_acc]\n",
    "val_loss = [_5155_val_loss,_20155_val_loss,_60155_val_loss,\n",
    "            _5555_val_loss,_20555_val_loss,_60555_val_loss]\n",
    "val_acc = [_5155_val_acc,_20155_val_acc,_60155_val_acc,\n",
    "           _5555_val_acc,_20555_val_acc,_60555_val_acc]\n",
    "le_name = ('Train: 5-way 1-shot Test: 5-way 5-shot','Train: 20-way 1-shot Test: 5-way 5-shot','Train: 60-way 1-shot Test: 5-way 5-shot',\n",
    "           'Train: 5-way 5-shot Test: 5-way 5-shot','Train: 20-way 5-shot Test: 5-way 5-shot','Train: 60-way 5-shot Test: 5-way 5-shot')\n",
    "title = 'Training and Validation results on Omniglot dataset'\n",
    "save_name = 'test-5way-5shot.jpg'\n",
    "sns.set(style=\"whitegrid\")\n",
    "draw_figure(training_acc,training_loss,val_acc,val_loss,le_name,title,save_name,save_op=True,alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
